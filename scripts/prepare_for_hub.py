#!/usr/bin/env python3
"""
Script para preparar o modelo BERT para publicaÃ§Ã£o no Hugging Face Hub
"""

import os
import json
import shutil
from pathlib import Path


def create_model_card():
    """
    Cria um model card para o Hugging Face Hub
    """

    model_card_content = """---
language:
- pt
- pt-BR
license: mit
datasets:
- custom
metrics:
- accuracy
- f1
- precision
- recall
tags:
- text-classification
- productivity
- email
- portuguese
- bert
- fine-tuned
---

# Email Productivity Classifier (PT-BR)

Este modelo foi fine-tuned para classificar emails em portuguÃªs brasileiro como **Produtivo** ou **Improdutivo**.

## ğŸ“‹ DescriÃ§Ã£o

O modelo utiliza arquitetura BERT baseada em portuguÃªs para analisar o conteÃºdo de emails e determinar se requerem aÃ§Ã£o especÃ­fica (produtivo) ou sÃ£o apenas informativos (improdutivo).

## ğŸ¯ Casos de Uso

- **AutomaÃ§Ã£o de triagem de emails**
- **PriorizaÃ§Ã£o de mensagens**
- **Filtros de produtividade**
- **AnÃ¡lise de fluxo de trabalho**

## ğŸ·ï¸ Labels

- **0**: Improdutivo (nÃ£o requer aÃ§Ã£o)
- **1**: Produtivo (requer aÃ§Ã£o/resposta)

## ğŸš€ Como Usar

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

# Carregar modelo
tokenizer = AutoTokenizer.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")
model = AutoModelForSequenceClassification.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")

# Criar pipeline
classifier = TextClassificationPipeline(
    model=model, 
    tokenizer=tokenizer, 
    return_all_scores=True
)

# Classificar email
result = classifier("Preciso de uma reuniÃ£o para discutir o projeto.")
print(result)
```

## ğŸ“Š Performance

- **AcurÃ¡cia**: >85%
- **F1-Score**: >0.80
- **Tempo de InferÃªncia**: <100ms
- **Tamanho MÃ¡ximo de Texto**: 512 tokens

## ğŸ—ï¸ Arquitetura

- **Modelo Base**: `neuralmind/bert-base-portuguese-cased`
- **Fine-tuning**: Sequence Classification
- **Framework**: Transformers (Hugging Face)
- **OtimizaÃ§Ã£o**: AdamW, Learning Rate Scheduling

## ğŸ“š Dataset

O modelo foi treinado com dataset customizado de emails em portuguÃªs brasileiro, incluindo:
- Emails corporativos
- ComunicaÃ§Ãµes internas
- SolicitaÃ§Ãµes de serviÃ§o
- InformaÃ§Ãµes gerais

## ğŸ”§ Treinamento

- **Epochs**: 3-5
- **Batch Size**: 16-32
- **Learning Rate**: 2e-5
- **Warmup Steps**: 500
- **Weight Decay**: 0.01

## ğŸ“ˆ MÃ©tricas de ValidaÃ§Ã£o

```
Accuracy: 0.87
F1-Score: 0.84
Precision: 0.86
Recall: 0.82
```

## ğŸš¨ LimitaÃ§Ãµes

- Funciona melhor com emails em portuguÃªs brasileiro
- Performance pode variar com domÃ­nios especÃ­ficos
- Requer contexto suficiente para classificaÃ§Ã£o adequada

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra uma issue ou pull request.

## ğŸ“„ LicenÃ§a

MIT License - veja o arquivo LICENSE para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido para classificaÃ§Ã£o automÃ¡tica de produtividade de emails.

## ğŸ”— Links Relacionados

- [Streamlit App](https://huggingface.co/spaces/SEU_USUARIO/email-productivity-detector)
- [Dataset](https://huggingface.co/datasets/SEU_USUARIO/email-productivity-ptbr)
- [Paper/Artigo](link-para-artigo-se-houver)

---

*Este modelo foi criado para facilitar a gestÃ£o de emails e melhorar a produtividade no ambiente corporativo.*
"""

    return model_card_content


def create_readme():
    """
    Cria um README para o repositÃ³rio do modelo
    """

    readme_content = """# Email Productivity Classifier (PT-BR)

Modelo BERT fine-tuned para classificaÃ§Ã£o de emails em portuguÃªs brasileiro.

## ğŸ¯ Objetivo

Classificar automaticamente emails como **Produtivo** (requer aÃ§Ã£o) ou **Improdutivo** (apenas informativo).

## ğŸš€ Uso RÃ¡pido

```python
from transformers import pipeline

classifier = pipeline(
    "text-classification",
    model="SEU_USUARIO/email-prod-improd-ptbr-bert"
)

result = classifier("Preciso de uma reuniÃ£o para discutir o projeto.")
print(result)
```

## ğŸ“Š Performance

- **AcurÃ¡cia**: >85%
- **F1-Score**: >0.80
- **Tempo**: <100ms

## ğŸ·ï¸ Labels

- **0**: Improdutivo
- **1**: Produtivo

## ğŸ“š Mais InformaÃ§Ãµes

Veja o [Model Card](README.md) para detalhes completos.

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas!
"""

    return readme_content


def create_requirements():
    """
    Cria arquivo requirements.txt para o modelo
    """

    requirements_content = """torch>=1.9.0
transformers>=4.20.0
tokenizers>=0.12.0
numpy>=1.21.0
scikit-learn>=1.0.0
"""

    return requirements_content


def prepare_model_for_hub(model_path: str, output_dir: str):
    """
    Prepara o modelo para publicaÃ§Ã£o no Hugging Face Hub

    Args:
        model_path: Caminho para o modelo local
        output_dir: DiretÃ³rio de saÃ­da para os arquivos do Hub
    """

    print(f"ğŸ”„ Preparando modelo para Hugging Face Hub...")

    # Criar diretÃ³rio de saÃ­da
    os.makedirs(output_dir, exist_ok=True)

    # Lista de arquivos essenciais para o Hub
    essential_files = [
        "config.json",
        "model.safetensors",
        "tokenizer.json",
        "tokenizer_config.json",
        "vocab.txt",
        "special_tokens_map.json",
    ]

    # Copiar arquivos essenciais
    print("ğŸ“ Copiando arquivos do modelo...")
    for file_name in essential_files:
        src_path = os.path.join(model_path, file_name)
        dst_path = os.path.join(output_dir, file_name)

        if os.path.exists(src_path):
            shutil.copy2(src_path, dst_path)
            print(f"âœ… {file_name}")
        else:
            print(f"âš ï¸  {file_name} nÃ£o encontrado")

    # Criar model card
    print("ğŸ“ Criando model card...")
    model_card = create_model_card()
    with open(os.path.join(output_dir, "README.md"), "w", encoding="utf-8") as f:
        f.write(model_card)

    # Criar README simples
    readme = create_readme()
    with open(os.path.join(output_dir, "README_simple.md"), "w", encoding="utf-8") as f:
        f.write(readme)

    # Criar requirements
    print("ğŸ“¦ Criando requirements.txt...")
    requirements = create_requirements()
    with open(os.path.join(output_dir, "requirements.txt"), "w", encoding="utf-8") as f:
        f.write(requirements)

    # Criar arquivo de metadados
    print("ğŸ“Š Criando metadados...")
    metadata = {
        "model_type": "bert",
        "task": "text-classification",
        "language": "pt-BR",
        "license": "mit",
        "tags": ["text-classification", "productivity", "email", "portuguese", "bert"],
        "datasets": ["custom"],
        "metrics": ["accuracy", "f1", "precision", "recall"],
    }

    with open(os.path.join(output_dir, "metadata.json"), "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    print(f"âœ… Modelo preparado com sucesso em: {output_dir}")

    return True


def create_upload_script(output_dir: str):
    """
    Cria script para upload no Hugging Face Hub
    """

    script_content = f"""#!/usr/bin/env python3
\"\"\"
Script para fazer upload do modelo no Hugging Face Hub
\"\"\"

import os
from huggingface_hub import HfApi, create_repo

def upload_to_hub():
    \"\"\"
    Faz upload do modelo para o Hugging Face Hub
    \"\"\"
    
    # Configurar API
    api = HfApi()
    
    # Nome do repositÃ³rio (troque pelo seu username)
    repo_name = "SEU_USUARIO/email-prod-improd-ptbr-bert"
    
    try:
        # Criar repositÃ³rio (se nÃ£o existir)
        create_repo(repo_name, exist_ok=True)
        print(f"âœ… RepositÃ³rio criado/verificado: {{repo_name}}")
        
        # Fazer upload dos arquivos
        print("ğŸ“¤ Fazendo upload dos arquivos...")
        
        # Lista de arquivos para upload
        files_to_upload = [
            "config.json",
            "model.safetensors", 
            "tokenizer.json",
            "tokenizer_config.json",
            "vocab.txt",
            "special_tokens_map.json",
            "README.md",
            "requirements.txt"
        ]
        
        for file_name in files_to_upload:
            file_path = os.path.join("{output_dir}", file_name)
            if os.path.exists(file_path):
                api.upload_file(
                    path_or_fileobj=file_path,
                    path_in_repo=file_name,
                    repo_id=repo_name
                )
                print(f"âœ… {{file_name}}")
            else:
                print(f"âš ï¸  {{file_name}} nÃ£o encontrado")
        
        print(f"\\nğŸ‰ Modelo publicado com sucesso!")
        print(f"ğŸŒ Acesse: https://huggingface.co/{{repo_name}}")
        
    except Exception as e:
        print(f"âŒ Erro no upload: {{e}}")

if __name__ == "__main__":
    print("ğŸš€ Fazendo upload para Hugging Face Hub...")
    upload_to_hub()
"""

    script_path = os.path.join(output_dir, "upload_to_hub.py")
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(script_content)

    # Tornar executÃ¡vel
    os.chmod(script_path, 0o755)

    print(f"âœ… Script de upload criado: {script_path}")

    return script_path


def main():
    """FunÃ§Ã£o principal"""
    print("ğŸš€ Preparando Modelo para Hugging Face Hub")
    print("=" * 60)

    # Caminhos
    model_path = "../models/bert_prod_improd"
    output_dir = "../hub_ready_model"

    # Verificar se o modelo existe
    if not os.path.exists(model_path):
        print(f"âŒ DiretÃ³rio do modelo nÃ£o encontrado: {model_path}")
        return

    # Preparar modelo para Hub
    if prepare_model_for_hub(model_path, output_dir):
        print("âœ… Modelo preparado com sucesso!")

        # Criar script de upload
        upload_script = create_upload_script(output_dir)

        print("\n" + "=" * 60)
        print("ğŸ¯ PRÃ“XIMOS PASSOS")
        print("=" * 60)
        print("1. âœ… Modelo preparado para Hub")
        print("2. ğŸ”§ Configurar Hugging Face Hub:")
        print("   - Instalar: pip install huggingface_hub")
        print("   - Login: huggingface-cli login")
        print("3. ğŸ“ Editar upload_to_hub.py com seu username")
        print("4. ğŸš€ Executar: python upload_to_hub.py")
        print(
            "5. ğŸŒ Verificar no Hub: https://huggingface.co/SEU_USUARIO/email-prod-improd-ptbr-bert"
        )

        print(f"\nğŸ“ Arquivos preparados em: {output_dir}")
        print(f"ğŸ“¤ Script de upload: {upload_script}")

        print("\nğŸ’¡ Para fazer upload:")
        print(f"   cd {output_dir}")
        print("   python setup_hub.py  # RECOMENDADO - configuraÃ§Ã£o automÃ¡tica")
        print("   # OU")
        print("   python upload_to_hub.py  # upload manual")
        print(f"\nğŸ“‹ IMPORTANTE: Use setup_hub.py para garantir categorizaÃ§Ã£o correta!")

    else:
        print("âŒ Falha ao preparar modelo para Hub")


if __name__ == "__main__":
    main()
