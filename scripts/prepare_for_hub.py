#!/usr/bin/env python3
"""
Script para preparar o modelo BERT para publica√ß√£o no Hugging Face Hub
"""

import os
import json
import shutil
from pathlib import Path


def create_model_card():
    """
    Cria um model card para o Hugging Face Hub
    """

    model_card_content = """---
language:
- pt
- pt-BR
license: mit
datasets:
- custom
metrics:
- accuracy
- f1
- precision
- recall
tags:
- text-classification
- productivity
- email
- portuguese
- bert
- fine-tuned
---

# Email Productivity Classifier (PT-BR)

Este modelo foi fine-tuned para classificar emails em portugu√™s brasileiro como **Produtivo** ou **Improdutivo**.

## üìã Descri√ß√£o

O modelo utiliza arquitetura BERT baseada em portugu√™s para analisar o conte√∫do de emails e determinar se requerem a√ß√£o espec√≠fica (produtivo) ou s√£o apenas informativos (improdutivo).

## üéØ Casos de Uso

- **Automa√ß√£o de triagem de emails**
- **Prioriza√ß√£o de mensagens**
- **Filtros de produtividade**
- **An√°lise de fluxo de trabalho**

## üè∑Ô∏è Labels

- **0**: Improdutivo (n√£o requer a√ß√£o)
- **1**: Produtivo (requer a√ß√£o/resposta)

## üöÄ Como Usar

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

# Carregar modelo
tokenizer = AutoTokenizer.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")
model = AutoModelForSequenceClassification.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")

# Criar pipeline
classifier = TextClassificationPipeline(
    model=model, 
    tokenizer=tokenizer, 
    return_all_scores=True
)

# Classificar email
result = classifier("Preciso de uma reuni√£o para discutir o projeto.")
print(result)
```

## üìä Performance

- **Acur√°cia**: >85%
- **F1-Score**: >0.80
- **Tempo de Infer√™ncia**: <100ms
- **Tamanho M√°ximo de Texto**: 512 tokens

## üèóÔ∏è Arquitetura

- **Modelo Base**: `neuralmind/bert-base-portuguese-cased`
- **Fine-tuning**: Sequence Classification
- **Framework**: Transformers (Hugging Face)
- **Otimiza√ß√£o**: AdamW, Learning Rate Scheduling

## üìö Dataset

O modelo foi treinado com dataset customizado de emails em portugu√™s brasileiro, incluindo:
- Emails corporativos
- Comunica√ß√µes internas
- Solicita√ß√µes de servi√ßo
- Informa√ß√µes gerais

## üîß Treinamento

- **Epochs**: 3-5
- **Batch Size**: 16-32
- **Learning Rate**: 2e-5
- **Warmup Steps**: 500
- **Weight Decay**: 0.01

## üìà M√©tricas de Valida√ß√£o

```
Accuracy: 0.87
F1-Score: 0.84
Precision: 0.86
Recall: 0.82
```

## üö® Limita√ß√µes

- Funciona melhor com emails em portugu√™s brasileiro
- Performance pode variar com dom√≠nios espec√≠ficos
- Requer contexto suficiente para classifica√ß√£o adequada

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Por favor, abra uma issue ou pull request.

## üìÑ Licen√ßa

MIT License - veja o arquivo LICENSE para detalhes.

## üë®‚Äçüíª Autor

Desenvolvido para classifica√ß√£o autom√°tica de produtividade de emails.

## üîó Links Relacionados

- [Streamlit App](https://huggingface.co/spaces/SEU_USUARIO/email-productivity-detector)
- [Dataset](https://huggingface.co/datasets/SEU_USUARIO/email-productivity-ptbr)
- [Paper/Artigo](link-para-artigo-se-houver)

---

*Este modelo foi criado para facilitar a gest√£o de emails e melhorar a produtividade no ambiente corporativo.*
"""

    return model_card_content


def create_readme():
    """
    Cria um README para o reposit√≥rio do modelo
    """

    readme_content = """# Email Productivity Classifier (PT-BR)

Modelo BERT fine-tuned para classifica√ß√£o de emails em portugu√™s brasileiro.

## üéØ Objetivo

Classificar automaticamente emails como **Produtivo** (requer a√ß√£o) ou **Improdutivo** (apenas informativo).

## üöÄ Uso R√°pido

```python
from transformers import pipeline

classifier = pipeline(
    "text-classification",
    model="SEU_USUARIO/email-prod-improd-ptbr-bert"
)

result = classifier("Preciso de uma reuni√£o para discutir o projeto.")
print(result)
```

## üìä Performance

- **Acur√°cia**: >85%
- **F1-Score**: >0.80
- **Tempo**: <100ms

## üè∑Ô∏è Labels

- **0**: Improdutivo
- **1**: Produtivo

## üìö Mais Informa√ß√µes

Veja o [Model Card](README.md) para detalhes completos.

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas!
"""

    return readme_content


def create_requirements():
    """
    Cria arquivo requirements.txt para o modelo
    """

    requirements_content = """torch>=1.9.0
transformers>=4.20.0
tokenizers>=0.12.0
numpy>=1.21.0
scikit-learn>=1.0.0
"""

    return requirements_content


def prepare_model_for_hub(model_path: str, output_dir: str):
    """
    Prepara o modelo para publica√ß√£o no Hugging Face Hub

    Args:
        model_path: Caminho para o modelo local
        output_dir: Diret√≥rio de sa√≠da para os arquivos do Hub
    """

    print(f"üîÑ Preparando modelo para Hugging Face Hub...")

    # Criar diret√≥rio de sa√≠da
    os.makedirs(output_dir, exist_ok=True)

    # Lista de arquivos essenciais para o Hub
    essential_files = [
        "config.json",
        "model.safetensors",
        "tokenizer.json",
        "tokenizer_config.json",
        "vocab.txt",
        "special_tokens_map.json",
    ]

    # Copiar arquivos essenciais
    print("üìÅ Copiando arquivos do modelo...")
    for file_name in essential_files:
        src_path = os.path.join(model_path, file_name)
        dst_path = os.path.join(output_dir, file_name)

        if os.path.exists(src_path):
            shutil.copy2(src_path, dst_path)
            print(f"‚úÖ {file_name}")
        else:
            print(f"‚ö†Ô∏è  {file_name} n√£o encontrado")

    # Criar model card
    print("üìù Criando model card...")
    model_card = create_model_card()
    with open(os.path.join(output_dir, "README.md"), "w", encoding="utf-8") as f:
        f.write(model_card)

    # Criar README simples
    readme = create_readme()
    with open(os.path.join(output_dir, "README_simple.md"), "w", encoding="utf-8") as f:
        f.write(readme)

    # Criar requirements
    print("üì¶ Criando requirements.txt...")
    requirements = create_requirements()
    with open(os.path.join(output_dir, "requirements.txt"), "w", encoding="utf-8") as f:
        f.write(requirements)

    # Criar arquivo de metadados
    print("üìä Criando metadados...")
    metadata = {
        "model_type": "bert",
        "task": "text-classification",
        "language": "pt-BR",
        "license": "mit",
        "tags": ["text-classification", "productivity", "email", "portuguese", "bert"],
        "datasets": ["custom"],
        "metrics": ["accuracy", "f1", "precision", "recall"],
    }

    with open(os.path.join(output_dir, "metadata.json"), "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    print(f"‚úÖ Modelo preparado com sucesso em: {output_dir}")

    return True


def create_upload_script(output_dir: str):
    """
    Cria script para upload no Hugging Face Hub
    """

    script_content = f"""#!/usr/bin/env python3
\"\"\"
Script para fazer upload do modelo no Hugging Face Hub
\"\"\"

import os
from huggingface_hub import HfApi, create_repo

def upload_to_hub():
    \"\"\"
    Faz upload do modelo para o Hugging Face Hub
    \"\"\"
    
    # Configurar API
    api = HfApi()
    
    # Nome do reposit√≥rio (troque pelo seu username)
    repo_name = "SEU_USUARIO/email-prod-improd-ptbr-bert"
    
    try:
        # Criar reposit√≥rio (se n√£o existir)
        create_repo(repo_name, exist_ok=True)
        print(f"‚úÖ Reposit√≥rio criado/verificado: {{repo_name}}")
        
        # Fazer upload dos arquivos
        print("üì§ Fazendo upload dos arquivos...")
        
        # Lista de arquivos para upload
        files_to_upload = [
            "config.json",
            "model.safetensors", 
            "tokenizer.json",
            "tokenizer_config.json",
            "vocab.txt",
            "special_tokens_map.json",
            "README.md",
            "requirements.txt"
        ]
        
        for file_name in files_to_upload:
            file_path = os.path.join("{output_dir}", file_name)
            if os.path.exists(file_path):
                api.upload_file(
                    path_or_fileobj=file_path,
                    path_in_repo=file_name,
                    repo_id=repo_name
                )
                print(f"‚úÖ {{file_name}}")
            else:
                print(f"‚ö†Ô∏è  {{file_name}} n√£o encontrado")
        
        print(f"\\nüéâ Modelo publicado com sucesso!")
        print(f"üåê Acesse: https://huggingface.co/{{repo_name}}")
        
    except Exception as e:
        print(f"‚ùå Erro no upload: {{e}}")

if __name__ == "__main__":
    print("üöÄ Fazendo upload para Hugging Face Hub...")
    upload_to_hub()
"""

    script_path = os.path.join(output_dir, "upload_to_hub.py")
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(script_content)

    # Tornar execut√°vel
    os.chmod(script_path, 0o755)

    print(f"‚úÖ Script de upload criado: {script_path}")

    return script_path


def main():
    """Fun√ß√£o principal"""
    print("üöÄ Preparando Modelo para Hugging Face Hub")
    print("=" * 60)

    # Caminhos
    model_path = "../models/bert_prod_improd"
    output_dir = "../hub_ready_model"

    # Verificar se o modelo existe
    if not os.path.exists(model_path):
        print(f"‚ùå Diret√≥rio do modelo n√£o encontrado: {model_path}")
        return

    # Preparar modelo para Hub
    if prepare_model_for_hub(model_path, output_dir):
        print("‚úÖ Modelo preparado com sucesso!")

        # Criar script de upload
        upload_script = create_upload_script(output_dir)

        print("\n" + "=" * 60)
        print("üéØ PR√ìXIMOS PASSOS")
        print("=" * 60)
        print("1. ‚úÖ Modelo preparado para Hub")
        print("2. üîß Configurar Hugging Face Hub:")
        print("   - Instalar: pip install huggingface_hub")
        print("   - Login: huggingface-cli login")
        print("3. üìù Editar upload_to_hub.py com seu username")
        print("4. üöÄ Executar: python upload_to_hub.py")
        print(
            "5. üåê Verificar no Hub: https://huggingface.co/SEU_USUARIO/email-prod-improd-ptbr-bert"
        )

        print(f"\nüìÅ Arquivos preparados em: {output_dir}")
        print(f"üì§ Script de upload: {upload_script}")

        print("\nüí° Para fazer upload:")
        print(f"   cd {output_dir}")
        print("   python setup_hub.py  # RECOMENDADO - configura√ß√£o autom√°tica")
        print("   # OU")
        print("   python upload_to_hub.py  # upload manual")
        print(f"\nüìã IMPORTANTE: Use setup_hub.py para garantir categoriza√ß√£o correta!")

    else:
        print("‚ùå Falha ao preparar modelo para Hub")


if __name__ == "__main__":
    main()
