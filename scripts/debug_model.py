#!/usr/bin/env python3
"""
Script de debug para investigar o que o modelo BERT est√° retornando
"""

import os
import sys
import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
)

# Adicionar o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def debug_model():
    """
    Debug do modelo para entender o que est√° sendo retornado
    """

    model_path = "../models/bert_prod_improd"

    print("üîç DEBUG DO MODELO BERT")
    print("=" * 50)

    try:
        # Carregar modelo
        print("üîÑ Carregando modelo...")
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)

        # Verificar configura√ß√£o
        print(f"üìä Configura√ß√£o do modelo:")
        print(f"   - id2label: {model.config.id2label}")
        print(f"   - label2id: {model.config.label2id}")
        print(f"   - num_labels: {model.config.num_labels}")

        # Criar pipeline
        print("\nüîÑ Criando pipeline...")
        pipeline = TextClassificationPipeline(
            model=model, tokenizer=tokenizer, return_all_scores=True, device=-1  # CPU
        )

        # Testar com texto simples
        test_text = "Preciso de uma reuni√£o para discutir o projeto."
        print(f"\nüß™ Testando com texto: '{test_text}'")

        # Fazer predi√ß√£o
        result = pipeline(test_text)
        print(f"\nüì§ Resultado bruto:")
        print(f"   Tipo: {type(result)}")
        print(f"   Conte√∫do: {result}")

        # Analisar estrutura
        if isinstance(result, list) and len(result) > 0:
            first_result = result[0]
            print(f"\nüîç Primeiro resultado:")
            print(f"   Tipo: {type(first_result)}")
            print(f"   Conte√∫do: {first_result}")

            if isinstance(first_result, list):
                for i, pred in enumerate(first_result):
                    print(f"\n   Predi√ß√£o {i}:")
                    print(f"     Tipo: {type(pred)}")
                    print(f"     Conte√∫do: {pred}")
                    if isinstance(pred, dict):
                        for key, value in pred.items():
                            print(f"     {key}: {value} (tipo: {type(value)})")

        # Testar com top_k
        print(f"\nüß™ Testando com top_k=None...")
        pipeline_top_k = TextClassificationPipeline(
            model=model, tokenizer=tokenizer, top_k=None, device=-1
        )

        result_top_k = pipeline_top_k(test_text)
        print(f"üì§ Resultado com top_k=None:")
        print(f"   Conte√∫do: {result_top_k}")

    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    debug_model()
