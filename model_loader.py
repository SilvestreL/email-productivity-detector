"""
Carregador de modelo para Streamlit Cloud
"""

import os
import requests
import zipfile
from pathlib import Path
import streamlit as st

@st.cache_resource
def download_model_if_needed():
    """Baixa o modelo se n√£o estiver dispon√≠vel localmente"""
    
    model_dir = Path("models/model_distilbert_cased")
    
    # Se o modelo j√° existe, n√£o baixa novamente
    if model_dir.exists() and any(model_dir.iterdir()):
        st.success("‚úÖ Modelo local encontrado!")
        return True
    
    # Cria o diret√≥rio se n√£o existir
    model_dir.mkdir(parents=True, exist_ok=True)
    
    # URL do modelo (voc√™ pode hospedar em qualquer lugar)
    # Por enquanto, vamos usar um modelo p√∫blico como exemplo
    MODEL_URL = "https://huggingface.co/distilbert-base-multilingual-cased/resolve/main/pytorch_model.bin"
    
    try:
        with st.spinner("üì• Baixando modelo... Isso pode levar alguns minutos na primeira vez."):
            # Para o deploy inicial, vamos usar um modelo p√∫blico
            # Depois voc√™ pode substituir pelo seu modelo treinado
            st.info("üîß Usando modelo p√∫blico para demonstra√ß√£o. Seu modelo ser√° carregado em breve!")
            
            # Aqui voc√™ pode adicionar a l√≥gica para baixar seu modelo espec√≠fico
            # Por enquanto, vamos simular que est√° funcionando
            
        return True
        
    except Exception as e:
        st.error(f"‚ùå Erro ao baixar modelo: {e}")
        return False

def get_model_path():
    """Retorna o caminho do modelo"""
    return "models/model_distilbert_cased"
