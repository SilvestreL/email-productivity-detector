import streamlit as st
import time
import re
import io
import os
import nltk
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
)
from functools import lru_cache
from typing import Dict, Literal, Tuple
import pdfplumber
import torch

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Email Productivity Classifier",
    page_icon="üìß",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# Constantes
MODEL_ID = "models/bert_prod_improd"  # Troque pelo seu modelo no Hub
ID2LABEL = {0: "Improdutivo", 1: "Produtivo"}


# Classificador Inteligente
class SmartEmailClassifier:
    """
    Classificador inteligente que combina modelo BERT com regras baseadas em palavras-chave
    """

    def __init__(self):
        # Categorias mais granulares
        self.categories = {
            "aniversario_parabens": {
                "keywords": [
                    "anivers√°rio",
                    "parab√©ns",
                    "felicidades",
                    "sa√∫de",
                    "muitos anos",
                    "feliz anivers√°rio",
                ],
                "priority": 1.0,  # Alta prioridade
                "response_type": "social_greeting",
            },
            "feriado_datas_especiais": {
                "keywords": [
                    "feriado",
                    "feriados",
                    "natal",
                    "ano novo",
                    "p√°scoa",
                    "carnaval",
                    "sexta-feira",
                    "fim de semana",
                    "f√©rias",
                    "descanso",
                    "aproveitem",
                    "desejo",
                    "desejos",
                    "excelente",
                    "feliz",
                    "boa",
                    "√≥timo",
                    "√≥tima",
                ],
                "priority": 1.0,  # Alta prioridade
                "response_type": "holiday_greeting",
            },
            "saudacoes_sociais": {
                "keywords": [
                    "bom dia",
                    "boa tarde",
                    "boa noite",
                    "ol√°",
                    "oi",
                    "ol√° a todos",
                    "oi pessoal",
                    "bom dia a todos",
                    "bom dia equipe",
                    "bom dia pessoal",
                    "apenas para informar",
                    "apenas informando",
                    "s√≥ para avisar",
                    "s√≥ informando",
                ],
                "priority": 0.95,  # Alta prioridade
                "response_type": "social_greeting",
            },
            "agradecimento": {
                "keywords": [
                    "obrigado",
                    "obrigada",
                    "valeu",
                    "agrade√ßo",
                    "agradecemos",
                    "grato",
                ],
                "priority": 0.9,
                "response_type": "acknowledgment",
            },
            "informacao_geral": {
                "keywords": [
                    "informar",
                    "comunicar",
                    "avisar",
                    "notificar",
                    "divulgar",
                ],
                "priority": 0.8,
                "response_type": "information",
            },
            "solicitacao_acao": {
                "keywords": [
                    "preciso",
                    "solicito",
                    "requer",
                    "necessito",
                    "urgente",
                    "reuni√£o",
                    "projeto",
                ],
                "priority": 0.7,
                "response_type": "action_required",
            },
            "problema_urgencia": {
                "keywords": [
                    "problema",
                    "erro",
                    "falha",
                    "cr√≠tico",
                    "emerg√™ncia",
                    "bug",
                    "sistema",
                ],
                "priority": 0.9,
                "response_type": "urgent_action",
            },
            "lembrete_agendamento": {
                "keywords": [
                    "lembrar",
                    "lembrete",
                    "agenda",
                    "hor√°rio",
                    "data",
                    "deadline",
                ],
                "priority": 0.8,
                "response_type": "reminder",
            },
        }

    def classify_with_keywords(self, text: str) -> Tuple[str, float, str]:
        """
        Classifica usando palavras-chave com alta confian√ßa
        """
        text_lower = text.lower()

        # Verificar cada categoria
        for category, config in self.categories.items():
            for keyword in config["keywords"]:
                if keyword in text_lower:
                    confidence = config["priority"]
                    response_type = config["response_type"]
                    return category, confidence, response_type

        # Se n√£o encontrar palavras-chave espec√≠ficas, retornar None
        return None, 0.0, None

    def smart_classify(self, text: str, model_prediction: Dict) -> Dict:
        """
        Classifica√ß√£o inteligente combinando palavras-chave e modelo BERT
        """

        # Primeiro, verificar se h√° palavras-chave √≥bvias
        keyword_category, keyword_confidence, response_type = (
            self.classify_with_keywords(text)
        )

        # Se encontrou categoria por palavras-chave com alta confian√ßa
        if keyword_category and keyword_confidence > 0.8:
            return {
                "category": keyword_category,
                "confidence": keyword_confidence,
                "response_type": response_type,
                "method": "keyword_based",
                "original_model_prediction": model_prediction,
                "correction_applied": True,
            }

        # Se n√£o, usar predi√ß√£o do modelo
        return {
            "category": model_prediction["category"],
            "confidence": model_prediction["confidence"],
            "response_type": "model_based",
            "method": "bert_model",
            "correction_applied": False,
        }

    def get_smart_response(
        self, classification: Dict, tone: str = "profissional"
    ) -> str:
        """
        Gera resposta inteligente baseada na classifica√ß√£o
        """
        category = classification["category"]
        response_type = classification.get("response_type", "default")

        responses = {
            "aniversario_parabens": {
                "profissional": "Obrigado pela mensagem de anivers√°rio! Desejamos muitas felicidades e sucesso.",
                "amig√°vel": "Que legal! Obrigado por compartilhar essa data especial! üéâ Muitas felicidades!",
                "formal": "Agradecemos a mensagem de anivers√°rio. Desejamos muitas felicidades e prosperidade.",
            },
            "agradecimento": {
                "profissional": "De nada! Ficamos felizes em poder ajudar.",
                "amig√°vel": "Por nada! üòä Foi um prazer!",
                "formal": "√â um prazer poder auxiliar. Ficamos √† disposi√ß√£o para futuras demandas.",
            },
            "informacao_geral": {
                "profissional": "Informa√ß√£o recebida e registrada. Obrigado pela comunica√ß√£o.",
                "amig√°vel": "Ok, anotado! üëç Obrigado por informar!",
                "formal": "Informa√ß√£o recebida e devidamente registrada. Agradecemos a comunica√ß√£o.",
            },
            "solicitacao_acao": {
                "profissional": "Solicita√ß√£o recebida. Vamos analisar e retornar em breve com as informa√ß√µes solicitadas.",
                "amig√°vel": "Beleza! Vou dar uma olhada nisso e te retorno! üòä",
                "formal": "Solicita√ß√£o recebida e est√° sendo processada. Retornaremos em breve com as informa√ß√µes solicitadas.",
            },
            "problema_urgencia": {
                "profissional": "Problema identificado. Nossa equipe t√©cnica foi notificada e est√° trabalhando na solu√ß√£o.",
                "amig√°vel": "Ops! Vou resolver isso rapidinho! üöÄ",
                "formal": "Problema identificado e nossa equipe t√©cnica foi imediatamente notificada. Estamos trabalhando na solu√ß√£o.",
            },
            "lembrete_agendamento": {
                "profissional": "Lembrete registrado. Confirmaremos o agendamento em breve.",
                "amig√°vel": "Perfeito! Vou anotar na agenda! üìÖ",
                "formal": "Lembrete registrado e ser√° confirmado em breve. Agradecemos a comunica√ß√£o.",
            },
            "feriado_datas_especiais": {
                "profissional": "Obrigado pela mensagem de feriado! Desejamos a todos um excelente descanso e aproveitem bastante!",
                "amig√°vel": "Que √≥timo! üéâ Obrigado por compartilhar essa energia positiva! Aproveitem muito o feriado!",
                "formal": "Agradecemos os votos de feriado. Desejamos a todos um excelente per√≠odo de descanso e renova√ß√£o.",
            },
            "saudacoes_sociais": {
                "profissional": "Bom dia! Obrigado pela mensagem. Ficamos √† disposi√ß√£o para futuras demandas.",
                "amig√°vel": "Oi! üòä Obrigado pela mensagem! Tudo bem por a√≠?",
                "formal": "Bom dia! Agradecemos a comunica√ß√£o. Ficamos √† disposi√ß√£o para futuras demandas.",
            },
        }

        # Retornar resposta baseada na categoria e tom
        if category in responses:
            return responses[category].get(tone, responses[category]["profissional"])

        # Resposta padr√£o se n√£o encontrar categoria espec√≠fica
        return "Mensagem recebida. Obrigado pelo contato."


# Instanciar classificador inteligente
smart_classifier = SmartEmailClassifier()


# Cache do modelo para evitar recarga
@st.cache_resource(show_spinner=True)
def get_classifier():
    """Carrega o modelo fine-tuned para classifica√ß√£o de emails"""
    try:
        # Carregar tokenizer e modelo local
        model_path = os.path.join(os.path.dirname(__file__), MODEL_ID)
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)

        # Configurar dispositivo
        device = 0 if torch.cuda.is_available() else -1

        # Criar pipeline
        return TextClassificationPipeline(
            model=model, tokenizer=tokenizer, return_all_scores=True, device=device
        )
    except Exception as e:
        st.error(f"Erro ao carregar modelo: {e}")
        st.info(
            "üí° Certifique-se de que o modelo est√° dispon√≠vel em models/bert_prod_improd"
        )
        return None


# Cache das stopwords em portugu√™s
@st.cache_resource(show_spinner=False)
def load_stopwords_pt():
    """Carrega stopwords em portugu√™s"""
    nltk.download("stopwords", quiet=True)
    return set(stopwords.words("portuguese"))


# Carregar stopwords
try:
    from nltk.corpus import stopwords

    STOP_PT = load_stopwords_pt()
except Exception as e:
    st.warning(f"Erro ao carregar stopwords: {e}")
    STOP_PT = set()


def preprocess(text: str) -> str:
    """
    Pr√©-processamento NLP para portugu√™s brasileiro

    Args:
        text: Texto a ser processado

    Returns:
        Texto processado
    """
    if not text:
        return ""

    # Normalizar espa√ßos
    text = re.sub(r"\s+", " ", text).strip()

    # Tokeniza√ß√£o simples por palavras
    tokens = re.findall(r"\w+|\S", text, flags=re.UNICODE)

    # Remover stopwords (case-insensitive)
    tokens = [t for t in tokens if t.lower() not in STOP_PT]

    # Opcional: stemming leve com RSLP
    # from nltk.stem import RSLPStemmer
    # stemmer = RSLPStemmer()
    # tokens = [stemmer.stem(t) if t.isalpha() else t for t in tokens]

    return " ".join(tokens)


def read_uploaded_file(uploaded) -> str:
    """
    L√™ arquivo enviado (.txt ou .pdf)

    Args:
        uploaded: Arquivo enviado via st.file_uploader

    Returns:
        Conte√∫do do arquivo como string
    """
    if uploaded is None:
        return ""

    try:
        if uploaded.type == "text/plain":
            # Arquivo .txt
            content = uploaded.read()
            return content.decode("utf-8")

        elif uploaded.type == "application/pdf":
            # Arquivo .pdf
            content = uploaded.read()
            with pdfplumber.open(io.BytesIO(content)) as pdf:
                text = ""
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                return text

        else:
            st.error(f"Tipo de arquivo n√£o suportado: {uploaded.type}")
            return ""

    except Exception as e:
        st.error(f"Erro ao ler arquivo: {e}")
        return ""


def classify_email(content: str) -> Dict:
    """
    Classifica email usando classificador inteligente (BERT + palavras-chave)

    Args:
        content: Conte√∫do do email

    Returns:
        Dict com category, confidence, scores e explanation
    """
    # Usar apenas o conte√∫do
    text = content.strip()

    # Se vazio, retornar categoria Improdutivo com confian√ßa 0.0
    if not text:
        return {
            "category": "Improdutivo",
            "confidence": 0.0,
            "scores": {"Produtivo": 0.0, "Improdutivo": 1.0},
            "explanation": "Nenhum conte√∫do recebido.",
        }

    # Pr√©-processar texto
    processed_text = preprocess(text)

    # Carregar classificador BERT
    classifier = get_classifier()

    if classifier is None:
        return {
            "category": "Erro",
            "confidence": 0.0,
            "scores": {"Produtivo": 0.0, "Improdutivo": 0.0},
            "explanation": "Erro ao carregar modelo.",
            "processed_text": processed_text,
            "original_text": text,
        }

    # Classificar com BERT (limitar tamanho do texto)
    result = classifier(processed_text[:4000])  # Evita textos muito longos

    # Mapear resultados do BERT
    scores = {}
    for pred in result[0]:
        # O modelo retorna labels como strings ("Improdutivo", "Produtivo")
        label_name = pred["label"]
        scores[label_name] = float(pred["score"])

    # Encontrar categoria com maior score do BERT
    bert_category = max(scores, key=scores.get)
    bert_confidence = scores[bert_category]

    # Predi√ß√£o do modelo BERT
    model_prediction = {"category": bert_category, "confidence": bert_confidence}

    # Usar classificador inteligente para corre√ß√£o
    smart_result = smart_classifier.smart_classify(text, model_prediction)

    # Determinar categoria final
    final_category = smart_result["category"]
    final_confidence = smart_result["confidence"]
    method_used = smart_result["method"]
    correction_applied = smart_result["correction_applied"]

    # Gerar explica√ß√£o inteligente
    if correction_applied:
        explanation = f"Classifica√ß√£o inteligente: {final_category} (corrigido de {bert_category}) com {final_confidence:.2%}."
    else:
        explanation = (
            f"Modelo BERT classificou como {final_category} com {final_confidence:.2%}."
        )

    return {
        "category": final_category,
        "confidence": final_confidence,
        "scores": scores,
        "explanation": explanation,
        "processed_text": processed_text,
        "original_text": text,
        "method": method_used,
        "correction_applied": correction_applied,
        "bert_prediction": bert_category,
        "smart_category": final_category,
    }


def suggest_reply(
    category: str, tone: str, content: str, classification_info: Dict = None
) -> Tuple[str, float, str]:
    """
    Sugere resposta inteligente baseada na categoria e contexto

    Args:
        category: Categoria do email (pode ser espec√≠fica como "aniversario_parabens")
        tone: Tom da resposta (profissional/amig√°vel/formal)
        content: Conte√∫do original
        classification_info: Informa√ß√µes adicionais da classifica√ß√£o

    Returns:
        Tuple com (reply, confidence, reasoning)
    """

    # Se temos informa√ß√µes de classifica√ß√£o inteligente, usar o classificador
    if classification_info and hasattr(smart_classifier, "get_smart_response"):
        try:
            reply = smart_classifier.get_smart_response(classification_info, tone)
            confidence = 0.95
            reasoning = f"Resposta inteligente para categoria '{category}' com tom {tone} - gerada automaticamente."
            return reply, confidence, reasoning
        except Exception as e:
            st.warning(f"Erro ao gerar resposta inteligente: {e}")
            # Continuar com templates tradicionais

    # Templates tradicionais para compatibilidade
    produtivo_templates = {
        "profissional": """Prezado(a),

Obrigado(a) pelo seu contato. Recebemos sua mensagem e confirmamos que requer nossa aten√ß√£o.

Para dar continuidade, precisamos de algumas informa√ß√µes:
- Qual o prazo esperado para esta demanda?
- H√° algum anexo que deveria acompanhar esta mensagem?
- Existe alguma prioridade espec√≠fica?

Atenciosamente,
Equipe de Atendimento""",
        "amig√°vel": """Oi!

Obrigado pelo contato! üòä 

Recebemos sua mensagem e vamos dar a aten√ß√£o necess√°ria.

Para organizarmos melhor, voc√™ poderia me informar:
- Qual o prazo que voc√™ tem em mente?
- Tem algum arquivo para anexar?
- √â algo urgente?

Qualquer d√∫vida, √© s√≥ falar!

Abra√ßos!""",
        "formal": """Exmo(a). Sr(a).,

Agradecemos o contato e informamos que sua comunica√ß√£o foi recebida e est√° sendo processada.

Para prosseguirmos adequadamente, solicitamos as seguintes informa√ß√µes:
- Prazo estimado para conclus√£o
- Documentos complementares, se houver
- N√≠vel de prioridade atribu√≠do

Em breve retornaremos com as informa√ß√µes solicitadas.

Respeitosamente,
Departamento de Atendimento""",
    }

    improdutivo_templates = {
        "profissional": """Prezado(a),

Obrigado(a) pelo seu contato. Recebemos sua mensagem e informamos que n√£o requer a√ß√£o espec√≠fica de nossa parte.

Agradecemos a comunica√ß√£o e ficamos √† disposi√ß√£o para futuras demandas que necessitem de nossa interven√ß√£o.

Atenciosamente,
Equipe de Comunica√ß√£o""",
        "amig√°vel": """Oi!

Obrigado pelo contato! üòä 

Recebemos sua mensagem e entendemos que n√£o precisa de nenhuma a√ß√£o nossa no momento.

Se precisar de algo espec√≠fico no futuro, √© s√≥ falar!

Abra√ßos!""",
        "formal": """Exmo(a). Sr(a).,

Agradecemos o contato e informamos que sua comunica√ß√£o foi recebida.

Conforme an√°lise, esta mensagem n√£o requer a√ß√£o espec√≠fica de nosso departamento no momento.

Ficamos √† disposi√ß√£o para futuras demandas que necessitem de nossa interven√ß√£o.

Respeitosamente,
Departamento de Comunica√ß√£o""",
    }

    # Selecionar template baseado na categoria
    if category in ["Produtivo", "solicitacao_acao", "problema_urgencia"]:
        reply = produtivo_templates.get(tone, produtivo_templates["profissional"])
        confidence = 0.90
        reasoning = f"Resposta autom√°tica para email {category} com tom {tone} - solicita confirma√ß√£o de objetivo/prazo/anexos."
    else:
        reply = improdutivo_templates.get(tone, improdutivo_templates["profissional"])
        confidence = 0.95
        reasoning = f"Resposta autom√°tica para email {category} com tom {tone} - agradece e indica que n√£o requer a√ß√£o."

    return reply, confidence, reasoning


# Interface principal
def main():
    st.title("üß† Email Intelligence Classifier")
    st.subheader(
        "Classifica√ß√£o Inteligente de Emails + Respostas Autom√°ticas Contextuais"
    )

    # Instru√ß√µes de uso
    st.markdown("### üìã Como usar (3 passos)")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.info(
            """
        **1Ô∏è‚É£ Envie arquivo ou cole texto**
        - Upload .txt/.pdf ou
        - Cole o conte√∫do do email
        """
        )

    with col2:
        st.info(
            """
        **2Ô∏è‚É£ Escolha o tom da resposta**
        - Profissional
        - Amig√°vel  
        - Formal
        """
        )

    with col3:
        st.info(
            """
        **3Ô∏è‚É£ Clique em Analisar**
        - Veja classifica√ß√£o inteligente
        - Receba resposta contextual
        """
        )

    st.markdown("---")

    # Inputs
    col1, col2 = st.columns([2, 1])

    with col1:
        content = st.text_area(
            "üìÑ Conte√∫do do Email",
            height=250,
            placeholder="Digite o conte√∫do do email aqui...",
            help="Conte√∫do completo do email",
        )

        # Upload de arquivo
        uploaded = st.file_uploader(
            "üìÅ Ou envie um arquivo (.txt ou .pdf)",
            type=["txt", "pdf"],
            help="Envie um arquivo .txt ou .pdf para an√°lise",
        )

    with col2:
        tone = st.selectbox(
            "üé≠ Tom da Resposta",
            ["profissional", "amig√°vel", "formal"],
            index=0,
            help="Tom da resposta sugerida",
        )

        st.markdown("### ‚ÑπÔ∏è Sobre")
        st.info(
            """
            **Modelo**: BERT PT-BR Fine-tuned + Classificador Inteligente  
            **M√©todo**: Text Classification + Palavras-chave  
            **Categorias**: Produtivo/Improdutivo + Espec√≠ficas  
            **Cache**: Ativado
            **NLP**: Stopwords PT-BR + Regras Inteligentes
            """
        )

    st.markdown("---")

    # Bot√£o de an√°lise
    if st.button("üîç Analisar Email", type="primary", use_container_width=True):
        # Determinar texto final
        final_content = ""

        if uploaded is not None:
            # Priorizar arquivo se enviado
            file_content = read_uploaded_file(uploaded)
            if file_content:
                final_content = file_content
                st.success(f"‚úÖ Arquivo processado: {uploaded.name}")
        else:
            # Usar texto colado
            final_content = content

        if not final_content:
            st.warning("‚ö†Ô∏è Por favor, digite o conte√∫do do email ou envie um arquivo.")
            return

        # Medir tempo de infer√™ncia
        start_time = time.perf_counter()

        # Classificar email
        with st.spinner("ü§ñ Classificando email..."):
            classification = classify_email(final_content)

        # Medir tempo
        inference_time = (time.perf_counter() - start_time) * 1000  # ms

        # Gerar resposta sugerida
        with st.spinner("üí¨ Gerando resposta..."):
            reply, reply_confidence, reasoning = suggest_reply(
                classification["category"], tone, final_content, classification
            )

        st.markdown("---")

        # Resultados em duas colunas
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown("### üìä Resumo")

            # Badge da categoria
            category = classification["category"]
            confidence = classification["confidence"]

            # Determinar cor e √≠cone baseado na categoria
            if category in [
                "aniversario_parabens",
                "agradecimento",
                "informacao_geral",
                "feriado_datas_especiais",
                "saudacoes_sociais",
            ]:
                st.info(
                    f"üéâ **{category.upper().replace('_', ' ')}** - {confidence:.1%}"
                )
            elif category in [
                "solicitacao_acao",
                "problema_urgencia",
                "lembrete_agendamento",
            ]:
                st.success(
                    f"‚úÖ **{category.upper().replace('_', ' ')}** - {confidence:.1%}"
                )
            elif category == "Produtivo":
                st.success(f"‚úÖ **PRODUTIVO** - {confidence:.1%}")
            elif category == "Improdutivo":
                st.error(f"üö® **IMPRODUTIVO** - {confidence:.1%}")
            else:
                st.warning(f"‚ö†Ô∏è **{category.upper()}** - {confidence:.1%}")

            # Mostrar se foi corrigido
            if classification.get("correction_applied"):
                st.info(
                    f"üîß **Corre√ß√£o Aplicada**: {classification['bert_prediction']} ‚Üí {classification['smart_category']}"
                )

            # Confian√ßa
            st.metric("Confian√ßa", f"{classification['confidence']:.1%}")

            # Tempo de infer√™ncia
            st.metric("Tempo de Infer√™ncia", f"{inference_time:.0f}ms")

            # Explica√ß√£o
            st.info(f"üí° {classification['explanation']}")

        with col2:
            st.markdown("### üìà Detalhes")

            # Scores brutos
            st.markdown("**Scores Detalhados:**")
            for label, score in classification["scores"].items():
                if label == "Produtivo":
                    st.progress(score, text=f"Produtivo: {score:.1%}")
                else:
                    st.progress(score, text=f"Improdutivo: {score:.1%}")

            # Informa√ß√µes t√©cnicas
            with st.expander("üîß Informa√ß√µes T√©cnicas"):
                tech_info = {
                    "modelo": "BERT Local (Fine-tuned) + Classificador Inteligente",
                    "m√©todo": classification.get("method", "text-classification"),
                    "tempo_inferencia_ms": round(inference_time, 2),
                    "scores_completos": classification["scores"],
                    "tamanho_texto_original": len(classification["original_text"]),
                    "tamanho_texto_processado": len(classification["processed_text"]),
                    "modelo_local": MODEL_ID,
                }

                # Adicionar informa√ß√µes de corre√ß√£o se aplic√°vel
                if classification.get("correction_applied"):
                    tech_info.update(
                        {
                            "correcao_aplicada": True,
                            "predicao_bert": classification["bert_prediction"],
                            "categoria_final": classification["smart_category"],
                            "metodo_final": classification["method"],
                        }
                    )

                st.json(tech_info)

        st.markdown("---")

        # Resposta sugerida
        st.markdown("### üí¨ Resposta Sugerida")

        col1, col2 = st.columns([3, 1])

        with col1:
            st.text_area(
                "Resposta Gerada",
                value=reply,
                height=200,
                disabled=True,
                help="Resposta sugerida baseada na classifica√ß√£o e tom selecionado",
            )

        with col2:
            st.metric("Confian√ßa da Resposta", f"{reply_confidence:.1%}")
            st.caption(f"üí≠ {reasoning}")

            # Bot√£o para copiar
            if st.button("üìã Copiar Resposta", use_container_width=True):
                st.code(reply, language=None)
                st.success("‚úÖ Resposta copiada! (Use Ctrl+C)")

    st.markdown("---")

    # Rodap√©
    st.markdown("### üìã Informa√ß√µes")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.info(
            """
            **üåê Plataforma**  
            Rodando em Hugging Face Spaces  
            SDK: Streamlit
            """
        )

    with col2:
        st.info(
            """
            **ü§ñ Modelo**  
            BERT PT-BR Fine-tuned + IA  
            Classifica√ß√£o Inteligente
            """
        )

    with col3:
        st.info(
            """
            **‚ö° Performance**  
            Cache ativado  
            Cold start: ~3-5s
            """
        )

    st.caption(
        "üí° **Dica**: A primeira execu√ß√£o pode levar alguns segundos (cold start). Modelo local + classificador inteligente ativado!"
    )


if __name__ == "__main__":
    main()
