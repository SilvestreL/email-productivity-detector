# ğŸ“§ Email Productivity Classifier

> **Classificador de Emails com IA usando BERT Fine-tuned em PortuguÃªs**  
> Sistema inteligente para classificar emails em Produtivo/Improdutivo e gerar respostas automÃ¡ticas

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.37.1+-red.svg)](https://streamlit.io)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-BERT-yellow.svg)](https://huggingface.co)
[![Spaces](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Spaces-blue.svg)](https://huggingface.co/spaces)

---

## ğŸ¯ **VisÃ£o Geral**

Sistema completo de classificaÃ§Ã£o de emails que:

- ğŸ¤– **Classifica emails** em Produtivo ou Improdutivo usando BERT fine-tuned em portuguÃªs
- ğŸ“ **Suporta upload** de arquivos .txt e .pdf alÃ©m de entrada de texto
- ğŸ”¤ **PrÃ©-processamento NLP** em portuguÃªs brasileiro (remoÃ§Ã£o de stopwords)
- ğŸ’¬ **Gera respostas automÃ¡ticas** baseadas na classificaÃ§Ã£o e tom selecionado
- ğŸŒ **Interface web** moderna e intuitiva com Streamlit
- âš¡ **Cache inteligente** para performance otimizada
- ğŸš€ **Pronto para Hugging Face Spaces** - zero configuraÃ§Ã£o
- ğŸ¯ **Modelo treinado** especificamente para classificaÃ§Ã£o de produtividade de emails

---

## ğŸš€ **Como Usar Online**

### **Hugging Face Spaces**

1. Acesse o link do Space: [ğŸ”— Link do Space]
2. **3 passos simples**:
   - **1ï¸âƒ£** Envie arquivo (.txt/.pdf) ou cole o texto do email
   - **2ï¸âƒ£** Escolha o tom da resposta (profissional, amigÃ¡vel, formal)
   - **3ï¸âƒ£** Clique em "Analisar Email"
3. Veja a classificaÃ§Ã£o e resposta sugerida

**Zero instalaÃ§Ã£o necessÃ¡ria!** ğŸ‰

---

## ğŸ¤– **Sobre o Modelo**

### **Modelo Fine-tuned**

- **Base**: `neuralmind/bert-base-portuguese-cased` (BERT em portuguÃªs)
- **Dataset**: Adaptado de spam.csv para classificaÃ§Ã£o de produtividade
- **Labels**: Produtivo (ham) vs Improdutivo (spam)
- **MÃ©tricas**: Accuracy e F1-score otimizados para classificaÃ§Ã£o de emails
- **Hub**: [ğŸ”— Link do modelo no Hugging Face Hub](https://huggingface.co/SEU_USUARIO/email-prod-improd-ptbr-bert)

### **Fine-tuning Process**

O modelo foi fine-tuned seguindo estas etapas:

1. **PreparaÃ§Ã£o do Dataset**: ConversÃ£o de spam.csv para formato de classificaÃ§Ã£o de produtividade
2. **Treinamento**: Fine-tuning do BERT portuguÃªs com 3 Ã©pocas
3. **ValidaÃ§Ã£o**: MÃ©tricas de accuracy e F1-score
4. **Deploy**: Upload para Hugging Face Hub

### **Reproduzir o Treinamento**

```bash
# 1. Preparar dataset
python scripts/prepare_dataset.py

# 2. Treinar modelo
python scripts/train.py

# 3. Configurar MODEL_ID no app.py
```

---

## ğŸ› ï¸ **Como Rodar Localmente**

### **PrÃ©-requisitos**

- Python 3.10+
- pip

### **InstalaÃ§Ã£o**

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd email-productivity-detector

# Instale as dependÃªncias
pip install -r requirements.txt

# Execute a aplicaÃ§Ã£o
streamlit run app.py
```

### **Acesso Local**

- ğŸŒ **Interface Web**: http://localhost:8501

---

## ğŸ—ï¸ **Stack TecnolÃ³gica**

```
ğŸ‘¤ UsuÃ¡rio â†’ ğŸŒ Streamlit â†’ ğŸ“ Upload/Texto â†’ ğŸ”¤ NLP PT-BR â†’ ğŸ¤– DistilBERT MNLI â†’ ğŸ’¬ Templates â†’ ğŸ“§ Resposta
```

### **Componentes**

- **Frontend**: Streamlit (interface web moderna)
- **Modelo**: BERT portuguÃªs fine-tuned (text classification)
- **ClassificaÃ§Ã£o**: Labels Produtivo/Improdutivo
- **Upload**: Suporte a .txt e .pdf
- **NLP**: PrÃ©-processamento em portuguÃªs (stopwords)
- **Respostas**: Templates baseados na categoria e tom
- **Cache**: @st.cache_resource para performance

---

## ğŸ“ **Estrutura do Projeto**

```
email-productivity-detector/
â”œâ”€â”€ ğŸ“„ README.md                    # Este arquivo
â”œâ”€â”€ ğŸš€ app.py                       # AplicaÃ§Ã£o principal (Streamlit)
â”œâ”€â”€ ğŸ“‹ requirements.txt             # DependÃªncias da aplicaÃ§Ã£o
â”œâ”€â”€ ğŸ“‹ requirements-train.txt       # DependÃªncias para treinamento
â”œâ”€â”€ ğŸ“ scripts/                     # Scripts de treinamento
â”‚   â”œâ”€â”€ prepare_dataset.py          # PreparaÃ§Ã£o do dataset
â”‚   â””â”€â”€ train.py                    # Treinamento do modelo
â”œâ”€â”€ ğŸ“ data/                        # Dados
â”‚   â”œâ”€â”€ spam.csv                    # Dataset original
â”‚   â””â”€â”€ processed/                  # Dataset processado
â”œâ”€â”€ ğŸ“ models/                      # Modelos treinados
â”‚   â””â”€â”€ email-prod-improd-ptbr-bert/ # Modelo fine-tuned
â””â”€â”€ ğŸ“ docs/                        # DocumentaÃ§Ã£o
    â”œâ”€â”€ API.md                      # DocumentaÃ§Ã£o da API (referÃªncia)
    â””â”€â”€ DEPLOY.md                   # Guia de deploy (referÃªncia)
```

---

## ğŸ§ª **Como Usar**

### **1. Interface Web - 3 Passos Simples**

#### **1ï¸âƒ£ Envie arquivo ou cole texto**

- **Upload**: Arquivos .txt ou .pdf
- **Texto**: Cole o conteÃºdo diretamente
- **Prioridade**: Arquivo tem prioridade sobre texto colado

#### **2ï¸âƒ£ Escolha o tom da resposta**

- **Profissional**: Tom corporativo formal
- **AmigÃ¡vel**: Tom descontraÃ­do e prÃ³ximo
- **Formal**: Tom institucional

#### **3ï¸âƒ£ Clique em Analisar**

- Veja a classificaÃ§Ã£o (Produtivo/Improdutivo)
- Receba resposta sugerida personalizada

### **2. Funcionalidades**

- âœ… **ClassificaÃ§Ã£o Fine-tuned**: Modelo treinado especificamente para emails
- âœ… **Upload de Arquivos**: .txt e .pdf suportados
- âœ… **PrÃ©-processamento NLP**: Stopwords em portuguÃªs brasileiro
- âœ… **Cache Inteligente**: Modelo carregado apenas uma vez
- âœ… **Templates Personalizados**: Respostas para Produtivo e Improdutivo
- âœ… **MÃºltiplos Tons**: Profissional, amigÃ¡vel, formal
- âœ… **MÃ©tricas Detalhadas**: ConfianÃ§a, scores, tempo, tamanho do texto
- âœ… **Interface Responsiva**: Funciona em desktop e mobile

---

## ğŸ”§ **Arquitetura TÃ©cnica**

### **Modelo**

- **Base**: `neuralmind/bert-base-portuguese-cased`
- **MÃ©todo**: Text Classification (Fine-tuned)
- **Labels**: `{0: "Improdutivo", 1: "Produtivo"}`
- **Cache**: `@st.cache_resource` para evitar recarga
- **Hub**: Modelo disponÃ­vel no Hugging Face Hub

### **ClassificaÃ§Ã£o**

```python
# Exemplo de uso
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

tokenizer = AutoTokenizer.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")
model = AutoModelForSequenceClassification.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")
classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)
result = classifier(text)
```

### **PrÃ©-processamento NLP**

- **Stopwords**: RemoÃ§Ã£o de palavras irrelevantes em portuguÃªs
- **NormalizaÃ§Ã£o**: Limpeza de espaÃ§os e caracteres especiais
- **TokenizaÃ§Ã£o**: Processamento por palavras
- **Opcional**: Stemming com RSLP (comentado no cÃ³digo)

### **Upload de Arquivos**

- **.txt**: DecodificaÃ§Ã£o UTF-8
- **.pdf**: ExtraÃ§Ã£o de texto com pdfplumber
- **Prioridade**: Arquivo > Texto colado

### **Respostas**

- **Produtivo**: Solicita confirmaÃ§Ã£o de objetivo/prazo/anexos
- **Improdutivo**: Agradece e indica que nÃ£o requer aÃ§Ã£o
- **Tons**: Profissional, amigÃ¡vel, formal
- **PersonalizaÃ§Ã£o**: Inclui assunto original

---

## ğŸ“Š **Performance**

- **Modelo**: BERT portuguÃªs fine-tuned
- **Dispositivo**: CPU/GPU automÃ¡tico
- **LatÃªncia**: < 1s por classificaÃ§Ã£o (apÃ³s cache)
- **Cold Start**: ~3-5s na primeira execuÃ§Ã£o
- **Cache**: Ativado para performance otimizada
- **NLP**: Processamento rÃ¡pido de stopwords
- **MÃ©tricas**: Accuracy e F1-score otimizados para classificaÃ§Ã£o de emails

---

## ğŸš€ **Deploy em Hugging Face Spaces**

### **ConfiguraÃ§Ã£o**

1. Criar novo Space no Hugging Face
2. Selecionar **SDK: Streamlit**
3. Upload dos arquivos:
   - `app.py`
   - `requirements.txt`
   - `README.md`

### **Arquivos NecessÃ¡rios**

- âœ… `app.py` - AplicaÃ§Ã£o principal
- âœ… `requirements.txt` - DependÃªncias
- âœ… `README.md` - DocumentaÃ§Ã£o

### **ConfiguraÃ§Ã£o AutomÃ¡tica**

O Space detecta automaticamente:

- SDK: Streamlit
- Entry point: `app.py`
- DependÃªncias: `requirements.txt`

---

## ğŸ” **Troubleshooting**

### **Problemas Comuns**

1. **Cold Start Lento**

   - â±ï¸ Primeira execuÃ§Ã£o: ~3-5s
   - âœ… ExecuÃ§Ãµes seguintes: < 1s (cache ativo)

2. **Modelo NÃ£o Carrega**

   - ğŸ”„ Recarregue a pÃ¡gina
   - ğŸ“¡ Verifique conexÃ£o com Hugging Face

3. **Erro de DependÃªncias**

   - ğŸ“‹ Verifique `requirements.txt`
   - ğŸ”„ Reinstale dependÃªncias

4. **Upload de Arquivo Falha**
   - ğŸ“ Verifique se Ã© .txt ou .pdf
   - ğŸ”¤ Certifique-se que o arquivo nÃ£o estÃ¡ corrompido

### **Logs**

```bash
# Local
streamlit run app.py --logger.level debug

# Hugging Face Spaces
# Logs disponÃ­veis na interface do Space
```

---

## ğŸ“š **DocumentaÃ§Ã£o Adicional**

- [ğŸ“– **API Reference**](docs/API.md) - DocumentaÃ§Ã£o da API (referÃªncia histÃ³rica)
- [ğŸš€ **Deploy Guide**](docs/DEPLOY.md) - Guia de deploy (referÃªncia histÃ³rica)

---

## ğŸ› ï¸ **Tecnologias**

- **Python 3.10+**: Linguagem principal
- **Streamlit 1.37.1+**: Interface web moderna
- **Hugging Face Transformers 4.43.3+**: BERT fine-tuned
- **PyTorch 2.6.0+**: Backend de ML
- **pdfplumber 0.11.4+**: ExtraÃ§Ã£o de texto de PDFs
- **NLTK 3.9.1+**: Processamento de linguagem natural
- **Text Classification**: Modelo fine-tuned para classificaÃ§Ã£o de emails

---

## ğŸ”§ **Desenvolvimento**

```bash
# Setup local
git clone <repository-url>
cd email-productivity-detector
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
pip install -r requirements.txt

# Executar aplicaÃ§Ã£o
streamlit run app.py
```

---

## ğŸ§ª **Testes**

```bash
# Teste local
streamlit run app.py

# Teste de funcionalidades
# 1. Teste com email produtivo
# 2. Teste com email improdutivo
# 3. Teste com upload de .txt
# 4. Teste com upload de .pdf
# 5. Teste com diferentes tons
# 6. Verificar cache e performance
```

---

## ğŸ“„ **LicenÃ§a**

Este projeto estÃ¡ licenciado sob a **MIT License**.

---

## ğŸ™ **Agradecimentos**

- **Hugging Face** pelo BERT portuguÃªs e infraestrutura
- **Streamlit** pela interface web moderna
- **NeuralMind** pelo modelo BERT em portuguÃªs
- **NLTK** pelo processamento de linguagem natural

---

**ğŸš€ Email Productivity Classifier - Pronto para Hugging Face Spaces!**
