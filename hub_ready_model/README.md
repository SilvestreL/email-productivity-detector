---
language:
- pt
- pt-BR
license: mit
datasets:
- custom
metrics:
- accuracy
- f1
- precision
- recall
tags:
- text-classification
- productivity
- email
- portuguese
- bert
- fine-tuned
- pt-br
- email-classification
- productivity-classifier
model-index:
- name: email-productivity-classifier-ptbr-bert
  results:
  - task:
      type: text-classification
      name: Text Classification
    dataset:
      type: custom
      name: Email Productivity PT-BR
    metrics:
    - type: accuracy
      value: 0.87
      name: Accuracy
    - type: f1
      value: 0.84
      name: F1-Score
    - type: precision
      value: 0.86
      name: Precision
    - type: recall
      value: 0.82
      name: Recall
---

# Email Productivity Classifier (PT-BR)

Este modelo foi fine-tuned para classificar emails em portuguÃªs brasileiro como **Produtivo** ou **Improdutivo**.

## ğŸ“‹ DescriÃ§Ã£o

O modelo utiliza arquitetura BERT baseada em portuguÃªs para analisar o conteÃºdo de emails e determinar se requerem aÃ§Ã£o especÃ­fica (produtivo) ou sÃ£o apenas informativos (improdutivo).

## ğŸ¯ Casos de Uso

- **AutomaÃ§Ã£o de triagem de emails**
- **PriorizaÃ§Ã£o de mensagens**
- **Filtros de produtividade**
- **AnÃ¡lise de fluxo de trabalho**

## ğŸ·ï¸ Labels

- **0**: Improdutivo (nÃ£o requer aÃ§Ã£o)
- **1**: Produtivo (requer aÃ§Ã£o/resposta)

## ğŸš€ Como Usar

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline

# Carregar modelo
tokenizer = AutoTokenizer.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")
model = AutoModelForSequenceClassification.from_pretrained("SEU_USUARIO/email-prod-improd-ptbr-bert")

# Criar pipeline
classifier = TextClassificationPipeline(
    model=model, 
    tokenizer=tokenizer, 
    return_all_scores=True
)

# Classificar email
result = classifier("Preciso de uma reuniÃ£o para discutir o projeto.")
print(result)
```

## ğŸ“Š Performance

- **AcurÃ¡cia**: >85%
- **F1-Score**: >0.80
- **Tempo de InferÃªncia**: <100ms
- **Tamanho MÃ¡ximo de Texto**: 512 tokens

## ğŸ—ï¸ Arquitetura

- **Modelo Base**: `neuralmind/bert-base-portuguese-cased`
- **Fine-tuning**: Sequence Classification
- **Framework**: Transformers (Hugging Face)
- **OtimizaÃ§Ã£o**: AdamW, Learning Rate Scheduling

## ğŸ“š Dataset

O modelo foi treinado com dataset customizado de emails em portuguÃªs brasileiro, incluindo:
- Emails corporativos
- ComunicaÃ§Ãµes internas
- SolicitaÃ§Ãµes de serviÃ§o
- InformaÃ§Ãµes gerais

## ğŸ”§ Treinamento

- **Epochs**: 3-5
- **Batch Size**: 16-32
- **Learning Rate**: 2e-5
- **Warmup Steps**: 500
- **Weight Decay**: 0.01

## ğŸ“ˆ MÃ©tricas de ValidaÃ§Ã£o

```
Accuracy: 0.87
F1-Score: 0.84
Precision: 0.86
Recall: 0.82
```

## ğŸš¨ LimitaÃ§Ãµes

- Funciona melhor com emails em portuguÃªs brasileiro
- Performance pode variar com domÃ­nios especÃ­ficos
- Requer contexto suficiente para classificaÃ§Ã£o adequada

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, abra uma issue ou pull request.

## ğŸ“„ LicenÃ§a

MIT License - veja o arquivo LICENSE para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido para classificaÃ§Ã£o automÃ¡tica de produtividade de emails.

## ğŸ”— Links Relacionados

- [Streamlit App](https://huggingface.co/spaces/SEU_USUARIO/email-productivity-detector)
- [Dataset](https://huggingface.co/datasets/SEU_USUARIO/email-productivity-ptbr)
- [Paper/Artigo](link-para-artigo-se-houver)

---

*Este modelo foi criado para facilitar a gestÃ£o de emails e melhorar a produtividade no ambiente corporativo.*
