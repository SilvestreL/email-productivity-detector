import streamlit as st
import time
import re
import io
import nltk
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
)
from functools import lru_cache
from typing import Dict, Literal, Tuple
import pdfplumber
import torch

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Email Productivity Classifier",
    page_icon="üìß",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# Constantes
MODEL_ID = "SEU_USUARIO/email-prod-improd-ptbr-bert"  # Troque pelo seu modelo no Hub
ID2LABEL = {0: "Improdutivo", 1: "Produtivo"}


# Cache do modelo para evitar recarga
@st.cache_resource(show_spinner=True)
def get_classifier():
    """Carrega o modelo fine-tuned para classifica√ß√£o de emails"""
    try:
        # Carregar tokenizer e modelo
        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)

        # Configurar dispositivo
        device = 0 if torch.cuda.is_available() else -1

        # Criar pipeline
        return TextClassificationPipeline(
            model=model, tokenizer=tokenizer, return_all_scores=True, device=device
        )
    except Exception as e:
        st.error(f"Erro ao carregar modelo: {e}")
        st.info("üí° Certifique-se de que o modelo est√° dispon√≠vel no Hugging Face Hub")
        return None


# Cache das stopwords em portugu√™s
@st.cache_resource(show_spinner=False)
def load_stopwords_pt():
    """Carrega stopwords em portugu√™s"""
    nltk.download("stopwords", quiet=True)
    return set(stopwords.words("portuguese"))


# Carregar stopwords
try:
    from nltk.corpus import stopwords

    STOP_PT = load_stopwords_pt()
except Exception as e:
    st.warning(f"Erro ao carregar stopwords: {e}")
    STOP_PT = set()


def preprocess(text: str) -> str:
    """
    Pr√©-processamento NLP para portugu√™s brasileiro

    Args:
        text: Texto a ser processado

    Returns:
        Texto processado
    """
    if not text:
        return ""

    # Normalizar espa√ßos
    text = re.sub(r"\s+", " ", text).strip()

    # Tokeniza√ß√£o simples por palavras
    tokens = re.findall(r"\w+|\S", text, flags=re.UNICODE)

    # Remover stopwords (case-insensitive)
    tokens = [t for t in tokens if t.lower() not in STOP_PT]

    # Opcional: stemming leve com RSLP
    # from nltk.stem import RSLPStemmer
    # stemmer = RSLPStemmer()
    # tokens = [stemmer.stem(t) if t.isalpha() else t for t in tokens]

    return " ".join(tokens)


def read_uploaded_file(uploaded) -> str:
    """
    L√™ arquivo enviado (.txt ou .pdf)

    Args:
        uploaded: Arquivo enviado via st.file_uploader

    Returns:
        Conte√∫do do arquivo como string
    """
    if uploaded is None:
        return ""

    try:
        if uploaded.type == "text/plain":
            # Arquivo .txt
            content = uploaded.read()
            return content.decode("utf-8")

        elif uploaded.type == "application/pdf":
            # Arquivo .pdf
            content = uploaded.read()
            with pdfplumber.open(io.BytesIO(content)) as pdf:
                text = ""
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                return text

        else:
            st.error(f"Tipo de arquivo n√£o suportado: {uploaded.type}")
            return ""

    except Exception as e:
        st.error(f"Erro ao ler arquivo: {e}")
        return ""


def classify_email(content: str) -> Dict:
    """
    Classifica email como Produtivo ou Improdutivo usando modelo fine-tuned

    Args:
        content: Conte√∫do do email

    Returns:
        Dict com category, confidence, scores e explanation
    """
    # Usar apenas o conte√∫do
    text = content.strip()

    # Se vazio, retornar categoria Improdutivo com confian√ßa 0.0
    if not text:
        return {
            "category": "Improdutivo",
            "confidence": 0.0,
            "scores": {"Produtivo": 0.0, "Improdutivo": 1.0},
            "explanation": "Nenhum conte√∫do recebido.",
        }

    # Pr√©-processar texto
    processed_text = preprocess(text)

    # Carregar classificador
    classifier = get_classifier()

    if classifier is None:
        return {
            "category": "Erro",
            "confidence": 0.0,
            "scores": {"Produtivo": 0.0, "Improdutivo": 0.0},
            "explanation": "Erro ao carregar modelo.",
            "processed_text": processed_text,
            "original_text": text,
        }

    # Classificar (limitar tamanho do texto)
    result = classifier(processed_text[:4000])  # Evita textos muito longos

    # Mapear resultados
    scores = {}
    for pred in result[0]:
        label_id = (
            int(pred["label"].split("_")[-1])
            if "LABEL" in pred["label"]
            else int(pred["label"])
        )
        label_name = ID2LABEL.get(label_id, pred["label"])
        scores[label_name] = float(pred["score"])

    # Encontrar categoria com maior score
    category = max(scores, key=scores.get)
    confidence = scores[category]

    # Gerar explica√ß√£o
    explanation = f"Modelo fine-tuned classificou como {category} com {confidence:.2%}."

    return {
        "category": category,
        "confidence": confidence,
        "scores": scores,
        "explanation": explanation,
        "processed_text": processed_text,
        "original_text": text,
    }


def suggest_reply(
    category: Literal["Produtivo", "Improdutivo"], tone: str, content: str
) -> Tuple[str, float, str]:
    """
    Sugere resposta baseada em templates (sem IA generativa)

    Args:
        category: Categoria do email (Produtivo/Improdutivo)
        tone: Tom da resposta (profissional/amig√°vel/formal)
        content: Conte√∫do original

    Returns:
        Tuple com (reply, confidence, reasoning)
    """

    # Templates para Produtivo
    produtivo_templates = {
        "profissional": """Prezado(a),

Obrigado(a) pelo seu contato. Recebemos sua mensagem e confirmamos que requer nossa aten√ß√£o.

Para dar continuidade, precisamos de algumas informa√ß√µes:
- Qual o prazo esperado para esta demanda?
- H√° algum anexo que deveria acompanhar esta mensagem?
- Existe alguma prioridade espec√≠fica?

Atenciosamente,
Equipe de Atendimento""",
        "amig√°vel": """Oi!

Obrigado pelo contato! üòä 

Recebemos sua mensagem e vamos dar a aten√ß√£o necess√°ria.

Para organizarmos melhor, voc√™ poderia me informar:
- Qual o prazo que voc√™ tem em mente?
- Tem algum arquivo para anexar?
- √â algo urgente?

Qualquer d√∫vida, √© s√≥ falar!

Abra√ßos!""",
        "formal": """Exmo(a). Sr(a).,

Agradecemos o contato e informamos que sua comunica√ß√£o foi recebida e est√° sendo processada.

Para prosseguirmos adequadamente, solicitamos as seguintes informa√ß√µes:
- Prazo estimado para conclus√£o
- Documentos complementares, se houver
- N√≠vel de prioridade atribu√≠do

Em breve retornaremos com as informa√ß√µes solicitadas.

Respeitosamente,
Departamento de Atendimento""",
    }

    # Templates para Improdutivo
    improdutivo_templates = {
        "profissional": """Prezado(a),

Obrigado(a) pelo seu contato. Recebemos sua mensagem e informamos que n√£o requer a√ß√£o espec√≠fica de nossa parte.

Agradecemos a comunica√ß√£o e ficamos √† disposi√ß√£o para futuras demandas que necessitem de nossa interven√ß√£o.

Atenciosamente,
Equipe de Comunica√ß√£o""",
        "amig√°vel": """Oi!

Obrigado pelo contato! üòä 

Recebemos sua mensagem e entendemos que n√£o precisa de nenhuma a√ß√£o nossa no momento.

Se precisar de algo espec√≠fico no futuro, √© s√≥ falar!

Abra√ßos!""",
        "formal": """Exmo(a). Sr(a).,

Agradecemos o contato e informamos que sua comunica√ß√£o foi recebida.

Conforme an√°lise, esta mensagem n√£o requer a√ß√£o espec√≠fica de nosso departamento no momento.

Ficamos √† disposi√ß√£o para futuras demandas que necessitem de nossa interven√ß√£o.

Respeitosamente,
Departamento de Comunica√ß√£o""",
    }

    # Selecionar template baseado na categoria
    if category == "Produtivo":
        reply = produtivo_templates.get(tone, produtivo_templates["profissional"])
        confidence = 0.90
        reasoning = f"Resposta autom√°tica para email {category} com tom {tone} - solicita confirma√ß√£o de objetivo/prazo/anexos."
    else:
        reply = improdutivo_templates.get(tone, improdutivo_templates["profissional"])
        confidence = 0.95
        reasoning = f"Resposta autom√°tica para email {category} com tom {tone} - agradece e indica que n√£o requer a√ß√£o."

    return reply, confidence, reasoning


# Interface principal
def main():
    st.title("üìß Email Productivity Classifier")
    st.subheader(
        "Classifica√ß√£o de Emails (Produtivo/Improdutivo) + Resposta Autom√°tica"
    )

    # Instru√ß√µes de uso
    st.markdown("### üìã Como usar (3 passos)")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.info(
            """
        **1Ô∏è‚É£ Envie arquivo ou cole texto**
        - Upload .txt/.pdf ou
        - Cole o conte√∫do do email
        """
        )

    with col2:
        st.info(
            """
        **2Ô∏è‚É£ Escolha o tom da resposta**
        - Profissional
        - Amig√°vel  
        - Formal
        """
        )

    with col3:
        st.info(
            """
        **3Ô∏è‚É£ Clique em Analisar**
        - Veja a classifica√ß√£o
        - Receba resposta sugerida
        """
        )

    st.markdown("---")

    # Inputs
    col1, col2 = st.columns([2, 1])

    with col1:
        content = st.text_area(
            "üìÑ Conte√∫do do Email",
            height=250,
            placeholder="Digite o conte√∫do do email aqui...",
            help="Conte√∫do completo do email",
        )

        # Upload de arquivo
        uploaded = st.file_uploader(
            "üìÅ Ou envie um arquivo (.txt ou .pdf)",
            type=["txt", "pdf"],
            help="Envie um arquivo .txt ou .pdf para an√°lise",
        )

    with col2:
        tone = st.selectbox(
            "üé≠ Tom da Resposta",
            ["profissional", "amig√°vel", "formal"],
            index=0,
            help="Tom da resposta sugerida",
        )

        st.markdown("### ‚ÑπÔ∏è Sobre")
        st.info(
            """
            **Modelo**: BERT PT-BR Fine-tuned  
            **M√©todo**: Text Classification  
            **Labels**: Produtivo/Improdutivo  
            **Cache**: Ativado
            **NLP**: Stopwords PT-BR
            """
        )

    st.markdown("---")

    # Bot√£o de an√°lise
    if st.button("üîç Analisar Email", type="primary", use_container_width=True):
        # Determinar texto final
        final_content = ""

        if uploaded is not None:
            # Priorizar arquivo se enviado
            file_content = read_uploaded_file(uploaded)
            if file_content:
                final_content = file_content
                st.success(f"‚úÖ Arquivo processado: {uploaded.name}")
        else:
            # Usar texto colado
            final_content = content

        if not final_content:
            st.warning("‚ö†Ô∏è Por favor, digite o conte√∫do do email ou envie um arquivo.")
            return

        # Medir tempo de infer√™ncia
        start_time = time.perf_counter()

        # Classificar email
        with st.spinner("ü§ñ Classificando email..."):
            classification = classify_email(final_content)

        # Medir tempo
        inference_time = (time.perf_counter() - start_time) * 1000  # ms

        # Gerar resposta sugerida
        with st.spinner("üí¨ Gerando resposta..."):
            reply, reply_confidence, reasoning = suggest_reply(
                classification["category"], tone, final_content
            )

        st.markdown("---")

        # Resultados em duas colunas
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown("### üìä Resumo")

            # Badge da categoria
            if classification["category"] == "Produtivo":
                st.success(f"‚úÖ **PRODUTIVO** - {classification['confidence']:.1%}")
            else:
                st.error(f"üö® **IMPRODUTIVO** - {classification['confidence']:.1%}")

            # Confian√ßa
            st.metric("Confian√ßa", f"{classification['confidence']:.1%}")

            # Tempo de infer√™ncia
            st.metric("Tempo de Infer√™ncia", f"{inference_time:.0f}ms")

            # Explica√ß√£o
            st.info(f"üí° {classification['explanation']}")

        with col2:
            st.markdown("### üìà Detalhes")

            # Scores brutos
            st.markdown("**Scores Detalhados:**")
            for label, score in classification["scores"].items():
                if label == "Produtivo":
                    st.progress(score, text=f"Produtivo: {score:.1%}")
                else:
                    st.progress(score, text=f"Improdutivo: {score:.1%}")

            # Informa√ß√µes t√©cnicas
            with st.expander("üîß Informa√ß√µes T√©cnicas"):
                st.json(
                    {
                        "modelo": MODEL_ID,
                        "m√©todo": "text-classification",
                        "tempo_inferencia_ms": round(inference_time, 2),
                        "scores_completos": classification["scores"],
                        "tamanho_texto_original": len(classification["original_text"]),
                        "tamanho_texto_processado": len(
                            classification["processed_text"]
                        ),
                    }
                )

        st.markdown("---")

        # Resposta sugerida
        st.markdown("### üí¨ Resposta Sugerida")

        col1, col2 = st.columns([3, 1])

        with col1:
            st.text_area(
                "Resposta Gerada",
                value=reply,
                height=200,
                disabled=True,
                help="Resposta sugerida baseada na classifica√ß√£o e tom selecionado",
            )

        with col2:
            st.metric("Confian√ßa da Resposta", f"{reply_confidence:.1%}")
            st.caption(f"üí≠ {reasoning}")

            # Bot√£o para copiar
            if st.button("üìã Copiar Resposta", use_container_width=True):
                st.code(reply, language=None)
                st.success("‚úÖ Resposta copiada! (Use Ctrl+C)")

    st.markdown("---")

    # Rodap√©
    st.markdown("### üìã Informa√ß√µes")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.info(
            """
            **üåê Plataforma**  
            Rodando em Hugging Face Spaces  
            SDK: Streamlit
            """
        )

    with col2:
        st.info(
            """
            **ü§ñ Modelo**  
            BERT PT-BR Fine-tuned  
            Text Classification
            """
        )

    with col3:
        st.info(
            """
            **‚ö° Performance**  
            Cache ativado  
            Cold start: ~3-5s
            """
        )

    st.caption(
        "üí° **Dica**: A primeira execu√ß√£o pode levar alguns segundos (cold start). Para modelo multil√≠ngue, altere MODEL_ID no c√≥digo."
    )


if __name__ == "__main__":
    main()
